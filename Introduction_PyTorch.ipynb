{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. PyTorch = Numpy + GPU + (other features)\n",
    "It is easy to convert numpy tensors to pytorch tensors and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = np.arange(5)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.Tensor([1,2,3])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Convert Numpy array to PyTorch Tensor\n",
    "t3 = torch.Tensor(t1)\n",
    "print(t3)\n",
    "# and back again\n",
    "t4 = t3.numpy()\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Switching between GPU and CPU is simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpu_t3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ac9e783eaf75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# and back to the cpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcpu_t3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_t3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gpu_t3' is not defined"
     ]
    }
   ],
   "source": [
    "# Bring PyTorch tensor on gpu by calling cuda()\n",
    "#gpu_t3 = t3.cuda() \n",
    "\n",
    "# and back to the cpu\n",
    "cpu_t3 = gpu_t3.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matrix multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.1730  1.5206  0.9610  1.7638  0.8436  1.1653  1.3729  1.0137  0.7185  1.3678\n",
       " 0.6372  1.1591  0.8026  1.3920  0.4620  0.8159  0.8937  0.8693  0.5985  1.0270\n",
       " 1.0437  1.7046  1.2585  1.5093  0.7270  1.0349  1.0800  1.0654  1.0014  1.5985\n",
       " 1.0852  1.6536  1.1415  1.5994  0.7474  1.0597  1.1966  1.0838  0.9169  1.5548\n",
       "[torch.FloatTensor of size 4x10]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.rand(4,5)\n",
    "t2 = torch.rand(5,10)\n",
    "t1.mm(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automatic gradient calculation\n",
    "Pytorch can calculate the gradient for you after you have done arbitrary computations. You only need to make sure to use torch Variables for your computations instead of torch Tensors.\n",
    "\n",
    "### Variable = Tensor + gradient features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4517  0.9266  0.6610  0.1498  0.2513\n",
       " 0.3308  0.3854  0.4631  0.0153  0.7253\n",
       " 0.9569  0.5930  0.1220  0.0519  0.8824\n",
       " 0.7728  0.6558  0.1840  0.1647  0.7962\n",
       "[torch.FloatTensor of size 4x5]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = Variable(t1) # creates a Variable from a Tensor\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.4517  3.9266  3.6610  3.1498  3.2513\n",
       " 3.3308  3.3854  3.4631  3.0153  3.7253\n",
       " 3.9569  3.5930  3.1220  3.0519  3.8824\n",
       " 3.7728  3.6558  3.1840  3.1647  3.7962\n",
       "[torch.FloatTensor of size 4x5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.data # contains out tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(v1.grad) # contains out gradient but it's currently none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define inputs\n",
    "x_tensor = torch.randn(10, 20)\n",
    "y_tensor = torch.randn(10, 5)\n",
    "\n",
    "x = Variable(x_tensor, requires_grad=False) # no gradient will be calculated for this variable\n",
    "y = Variable(y_tensor, requires_grad=False) # no gradient will be calculated for this variable\n",
    "\n",
    "# define some weights\n",
    "w = Variable(torch.randn(20, 5), requires_grad=True) # gradient will be calculated for this variable\n",
    "\n",
    "# get variable tensor\n",
    "print(type(w.data))  # torch.FloatTensor\n",
    "# get variable gradient\n",
    "print(w.grad)  # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.5055  1.5055  1.5055  1.5055  1.5055\n",
      "-1.3779 -1.3779 -1.3779 -1.3779 -1.3779\n",
      " 0.9115  0.9115  0.9115  0.9115  0.9115\n",
      "-1.3805 -1.3805 -1.3805 -1.3805 -1.3805\n",
      "-0.3577 -0.3577 -0.3577 -0.3577 -0.3577\n",
      " 1.5802  1.5802  1.5802  1.5802  1.5802\n",
      "-0.6379 -0.6379 -0.6379 -0.6379 -0.6379\n",
      " 0.3137  0.3137  0.3137  0.3137  0.3137\n",
      "-0.2449 -0.2449 -0.2449 -0.2449 -0.2449\n",
      " 0.6991  0.6991  0.6991  0.6991  0.6991\n",
      "-2.1097 -2.1097 -2.1097 -2.1097 -2.1097\n",
      "-0.3521 -0.3521 -0.3521 -0.3521 -0.3521\n",
      " 0.4066  0.4066  0.4066  0.4066  0.4066\n",
      "-0.1653 -0.1653 -0.1653 -0.1653 -0.1653\n",
      "-1.6496 -1.6496 -1.6496 -1.6496 -1.6496\n",
      "-0.3047 -0.3047 -0.3047 -0.3047 -0.3047\n",
      "-0.7570 -0.7570 -0.7570 -0.7570 -0.7570\n",
      "-0.2626 -0.2626 -0.2626 -0.2626 -0.2626\n",
      " 1.2828  1.2828  1.2828  1.2828  1.2828\n",
      "-0.4467 -0.4467 -0.4467 -0.4467 -0.4467\n",
      "[torch.FloatTensor of size 20x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we need a function for which we want to calculate a gradient \n",
    "# => This will always be our cost function\n",
    "\n",
    "loss = torch.mean(y - x.mm(w))\n",
    "\n",
    "### HERE IS ALL THE MAGIC - calculate all gradients in one line ###\n",
    "loss.backward()\n",
    "\n",
    "# results can be found in the grad attribute of each variable\n",
    "print(w.grad)  # some gradients\n",
    "\n",
    "# See what happends when you run loss.backward() several times (just execute the cell several times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have to actively set the gradients to zero after each backpropagation step.\n",
    "w.grad.data.zero_();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build and train our first neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nn is called the \"Neural Network Package\" and contains all modules which are related to NNs.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define x and y trainings data\n",
    "x = Variable(torch.randn(10, 20), requires_grad=False)\n",
    "y = Variable(torch.randn(10, 3), requires_grad=False)\n",
    "\n",
    "# define some weights\n",
    "w1 = Variable(torch.randn(20, 5), requires_grad=True)\n",
    "w2 = Variable(torch.randn(5, 3), requires_grad=True)\n",
    "\n",
    "learning_rate = 0.1\n",
    "loss_fn = torch.nn.MSELoss() # F.mse_loss() functional interface\n",
    "optimizer = torch.optim.SGD([w1, w2], lr=learning_rate)\n",
    "\n",
    "\n",
    "for step in range(5):\n",
    "    \n",
    "    # forward pass\n",
    "    pred = F.sigmoid(x.mm(w1))\n",
    "    pred = F.sigmoid(pred.mm(w2))\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # instead of setting all gradients to zero manually,\n",
    "    # we can use an optimizer function\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # backward pass => calculate gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # do one step of st. gradient descent update\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And now how can I use it to make predictions?  \n",
    "You have to do it \"by hand\" meaning you need to call the function sigmoid twice with w1 und w2.  \n",
    "But there is also a more convenient way: Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Building a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### 1. Method: Sequential #### \n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10,5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-0c472809e3bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5016\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(torch.rand(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 0.2451  0.1578 -0.0938  0.2572 -0.2049 -0.1006  0.0939 -0.2246  0.2534 -0.0706\n",
       "-0.2203 -0.0450 -0.2360  0.1251  0.1969  0.1551  0.0931 -0.2479 -0.2977  0.2848\n",
       "-0.0695  0.2488 -0.0392  0.2784 -0.2997 -0.1833 -0.2859 -0.1568 -0.0128  0.1833\n",
       " 0.0865  0.0096 -0.0898  0.0710  0.1341 -0.2149 -0.1091 -0.0093 -0.0908 -0.2079\n",
       "-0.2374  0.2335 -0.2905  0.2679  0.2320  0.0981  0.1184  0.3135  0.1505  0.0948\n",
       "[torch.FloatTensor of size 5x10]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "-0.0079 -0.2133 -0.0082 -0.3442 -0.1578\n",
       "[torch.FloatTensor of size 1x5]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RoboRacer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # always first line\n",
    "        \n",
    "        # define all layers you want to use later here\n",
    "        self.linear1 = nn.Linear(10,5)\n",
    "        self.linear2 = nn.Linear(5,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # call all layers in the right order here and return the result\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "robo = RoboRacer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4070\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robo(Variable(torch.rand(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoboRacer(\n",
      "  (linear1): Linear(in_features=10, out_features=5)\n",
      "  (linear2): Linear(in_features=5, out_features=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(robo) # useful to get a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
